#!/usr/bin/env python3
"""æ¨¡å‹éªŒè¯è„šæœ¬ï¼šæ£€æŸ¥è®­ç»ƒå¥½çš„æ¨¡å‹"""
import os
import sys
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

sys.path.append(os.getcwd())
from datasets.segmentation_dataset import LVWallDataset
from segmentation.segmentation_utils import get_model_and_optim
from easydict import EasyDict

def load_model(model_path):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    config = EasyDict(dict(
        architecture='Unet',
        encoder='resnet18',
        img_shape=(224, 224),
    ))
    
    device = torch.device('cpu')
    model, _ = get_model_and_optim(config, device=device)
    
    # åŠ è½½æƒé‡
    state_dict = torch.load(model_path, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()
    
    return model, device

def test_model(model_path):
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½"""
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹: {os.path.basename(model_path)}")
    print(f"ğŸ“ è·¯å¾„: {model_path}")
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(model_path):
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨!")
        return
    
    file_size = os.path.getsize(model_path) / (1024*1024)  # MB
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
    
    try:
        # åŠ è½½æ¨¡å‹
        model, device = load_model(model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # ç»Ÿè®¡å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"ğŸ“ˆ æ¨¡å‹å‚æ•°: {total_params:,} æ€»å‚æ•°, {trainable_params:,} å¯è®­ç»ƒå‚æ•°")
        
        # æµ‹è¯•æ¨ç†
        print("\nğŸ§ª æµ‹è¯•æ¨ç†...")
        test_input = torch.randn(1, 3, 224, 224)  # æ‰¹å¤§å°1ï¼Œ3é€šé“ï¼Œ224x224
        
        with torch.no_grad():
            output = model(test_input)
            print(f"âœ… æ¨ç†æˆåŠŸ! è¾“å…¥: {test_input.shape}, è¾“å‡º: {output.shape}")
            print(f"ğŸ“Š è¾“å‡ºèŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
        
        # ç”¨çœŸå®æ•°æ®æµ‹è¯•
        print("\nğŸ–¼ï¸  æµ‹è¯•çœŸå®æ•°æ®...")
        ds = LVWallDataset(split='test', id_fold=0, img_size=(224,224))
        x, y_true = ds[0]
        
        x_tensor = torch.from_numpy(x).unsqueeze(0).float()  # æ·»åŠ batchç»´åº¦
        with torch.no_grad():
            y_pred = torch.sigmoid(model(x_tensor))
            
        print(f"âœ… çœŸå®æ•°æ®æ¨ç†æˆåŠŸ!")
        print(f"ğŸ“Š é¢„æµ‹æ©ç èŒƒå›´: [{y_pred.min():.4f}, {y_pred.max():.4f}]")
        print(f"ğŸ“Š çœŸå®æ©ç : {y_true.sum()} ä¸ªå‰æ™¯åƒç´ ")
        print(f"ğŸ“Š é¢„æµ‹æ©ç : {(y_pred > 0.5).sum()} ä¸ªå‰æ™¯åƒç´ ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("=" * 60)
    print("ğŸ¤– å¿ƒè‚Œæ¢—æ­»æ£€æµ‹æ¨¡å‹éªŒè¯")
    print("=" * 60)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
    model_files = []
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.pth'):
                model_files.append(os.path.join(root, file))
    
    if not model_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶!")
        return
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶:")
    for i, path in enumerate(model_files):
        print(f"  {i+1}. {path}")
    
    # æµ‹è¯•æœ€æ–°çš„æ¨¡å‹ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰
    latest_model = max([f for f in model_files if 'segment_ckpt_5folds' in f], key=os.path.getmtime)
    
    print(f"\nğŸ¯ æµ‹è¯•æœ€æ–°æ¨¡å‹:")
    success = test_model(latest_model)
    
    if success:
        print(f"\nğŸ‰ æ¨¡å‹éªŒè¯æˆåŠŸ! æ¨¡å‹å·²å°±ç»ªï¼Œå¯ç”¨äºæ¨ç†ã€‚")
        print(f"ğŸ’¡ ä½¿ç”¨æ–¹æ³•: åŠ è½½ {os.path.basename(latest_model)} è¿›è¡Œå¿ƒè‚Œåˆ†å‰²æ¨ç†")
    else:
        print(f"\nâŒ æ¨¡å‹éªŒè¯å¤±è´¥!")

if __name__ == '__main__':
    main()
